{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPv3CZdCugIenYvMNVeeCT/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/porcruso/transformers/blob/main/stable-diffusion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFR6ZKQ9kPqo",
        "outputId": "162622dc-babb-4e1c-a60c-a01d1df40147"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-webui/extensions\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ltx0I4M4lU4a",
        "outputId": "897d3f09-8399-4644-8122-366452890c9f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 34968, done.\u001b[K\n",
            "remote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 34968 (delta 6), reused 3 (delta 3), pack-reused 34954 (from 2)\u001b[K\n",
            "Receiving objects: 100% (34968/34968), 35.56 MiB | 19.30 MiB/s, done.\n",
            "Resolving deltas: 100% (24405/24405), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-webui/\n",
        "!git clone https://github.com/continue-revolution/sd-webui-animatediff extensions/sd-webui-animatediff\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDTJzlaXnjhb",
        "outputId": "e6aea848-e523-482a-ce5b-34e1f46e3106"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui\n",
            "fatal: destination path 'extensions/sd-webui-animatediff' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-webui/\n",
        "!mkdir -p extensions/sd-webui-animatediff/model\n",
        "!wget https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15.ckpt -O extensions/sd-webui-animatediff/model/mm_sd_v15.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vthlb4jyntlz",
        "outputId": "89bb535b-f0d4-499c-b102-b5e724ca28f1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui\n",
            "--2025-05-16 01:30:17--  https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 18.164.174.23, 18.164.174.17, 18.164.174.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.164.174.23|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/80/a9/80a9efd8e3732d097f2777edd953760ce288e2370fb8a8bb4803c0f8f29dca40/cf16ea656cb16124990c8e2c70a29c793f9841f3a2223073fac8bd89ebd9b69a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mm_sd_v15.ckpt%3B+filename%3D%22mm_sd_v15.ckpt%22%3B&Expires=1747362617&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzM2MjYxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy84MC9hOS84MGE5ZWZkOGUzNzMyZDA5N2YyNzc3ZWRkOTUzNzYwY2UyODhlMjM3MGZiOGE4YmI0ODAzYzBmOGYyOWRjYTQwL2NmMTZlYTY1NmNiMTYxMjQ5OTBjOGUyYzcwYTI5Yzc5M2Y5ODQxZjNhMjIyMzA3M2ZhYzhiZDg5ZWJkOWI2OWE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qINHU7oV5WeKW0pAnq%7ET4kBjAIlZ%7E3dfSk3%7EjAm-mYWiSLjVwTKfp%7EwHGp26lzUNXTNlmEuePfp5FNI0sUQlnsMbPTQdacdTLjGfO6tmqg%7E%7EsUY-fEJZmEHNo-iYZJ12sCgyi0eZEeVSXzWiUpCZ0TuD%7El%7E0I4vHfT20sII9m41lKMJ3wxx2oQdj1PTuLEcJ84utzT%7EF4UjOq7PD%7E0NDfx6bB4n8vuPsnddPrNeM9XtcMD2OhiYSXw6er1csMFRwjUUPylza3Fwo47Rcj85voZ4URvcJuA5q18OGTRFe0YCR6yuXuT2U3D-SKBB--dWvNWVy8nF0Me2F5gShUtcGhg__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-05-16 01:30:17--  https://cdn-lfs.hf.co/repos/80/a9/80a9efd8e3732d097f2777edd953760ce288e2370fb8a8bb4803c0f8f29dca40/cf16ea656cb16124990c8e2c70a29c793f9841f3a2223073fac8bd89ebd9b69a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mm_sd_v15.ckpt%3B+filename%3D%22mm_sd_v15.ckpt%22%3B&Expires=1747362617&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzM2MjYxN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy84MC9hOS84MGE5ZWZkOGUzNzMyZDA5N2YyNzc3ZWRkOTUzNzYwY2UyODhlMjM3MGZiOGE4YmI0ODAzYzBmOGYyOWRjYTQwL2NmMTZlYTY1NmNiMTYxMjQ5OTBjOGUyYzcwYTI5Yzc5M2Y5ODQxZjNhMjIyMzA3M2ZhYzhiZDg5ZWJkOWI2OWE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=qINHU7oV5WeKW0pAnq%7ET4kBjAIlZ%7E3dfSk3%7EjAm-mYWiSLjVwTKfp%7EwHGp26lzUNXTNlmEuePfp5FNI0sUQlnsMbPTQdacdTLjGfO6tmqg%7E%7EsUY-fEJZmEHNo-iYZJ12sCgyi0eZEeVSXzWiUpCZ0TuD%7El%7E0I4vHfT20sII9m41lKMJ3wxx2oQdj1PTuLEcJ84utzT%7EF4UjOq7PD%7E0NDfx6bB4n8vuPsnddPrNeM9XtcMD2OhiYSXw6er1csMFRwjUUPylza3Fwo47Rcj85voZ4URvcJuA5q18OGTRFe0YCR6yuXuT2U3D-SKBB--dWvNWVy8nF0Me2F5gShUtcGhg__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.169.231.4, 3.169.231.87, 3.169.231.115, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.169.231.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1672133921 (1.6G) [binary/octet-stream]\n",
            "Saving to: ‘extensions/sd-webui-animatediff/model/mm_sd_v15.ckpt’\n",
            "\n",
            "extensions/sd-webui 100%[===================>]   1.56G   112MB/s    in 7.8s    \n",
            "\n",
            "2025-05-16 01:30:25 (203 MB/s) - ‘extensions/sd-webui-animatediff/model/mm_sd_v15.ckpt’ saved [1672133921/1672133921]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/stable-diffusion-webui/extensions\n",
        "!git clone https://github.com/Mikubill/sd-webui-controlnet\n",
        "!git clone https://github.com/camenduru/sd-civitai-browser\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuLFBGvPn9OK",
        "outputId": "85b11b6c-f6ff-4d83-a8ac-72e524119b01"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui/extensions\n",
            "Cloning into 'sd-webui-controlnet'...\n",
            "remote: Enumerating objects: 9979, done.\u001b[K\n",
            "remote: Counting objects: 100% (724/724), done.\u001b[K\n",
            "remote: Compressing objects: 100% (99/99), done.\u001b[K\n",
            "remote: Total 9979 (delta 669), reused 625 (delta 625), pack-reused 9255 (from 2)\u001b[K\n",
            "Receiving objects: 100% (9979/9979), 18.11 MiB | 18.07 MiB/s, done.\n",
            "Resolving deltas: 100% (5980/5980), done.\n",
            "Cloning into 'sd-civitai-browser'...\n",
            "remote: Enumerating objects: 163, done.\u001b[K\n",
            "remote: Counting objects: 100% (42/42), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 163 (delta 35), reused 26 (delta 26), pack-reused 121 (from 1)\u001b[K\n",
            "Receiving objects: 100% (163/163), 38.83 KiB | 641.00 KiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p extensions/sd-webui-animatediff/model\n",
        "!wget https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15.ckpt -O extensions/sd-webui-animatediff/model/mm_sd_v15.ckpt\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vpLpLvo3qqAw",
        "outputId": "46a7ada2-cdf7-4d3b-db55-3b30668c5e5c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-16 01:17:27--  https://huggingface.co/guoyww/animatediff/resolve/main/mm_sd_v15.ckpt\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.246.71, 108.138.246.67, 108.138.246.79, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.246.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.hf.co/repos/80/a9/80a9efd8e3732d097f2777edd953760ce288e2370fb8a8bb4803c0f8f29dca40/cf16ea656cb16124990c8e2c70a29c793f9841f3a2223073fac8bd89ebd9b69a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mm_sd_v15.ckpt%3B+filename%3D%22mm_sd_v15.ckpt%22%3B&Expires=1747361847&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzM2MTg0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy84MC9hOS84MGE5ZWZkOGUzNzMyZDA5N2YyNzc3ZWRkOTUzNzYwY2UyODhlMjM3MGZiOGE4YmI0ODAzYzBmOGYyOWRjYTQwL2NmMTZlYTY1NmNiMTYxMjQ5OTBjOGUyYzcwYTI5Yzc5M2Y5ODQxZjNhMjIyMzA3M2ZhYzhiZDg5ZWJkOWI2OWE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=SmzOUWxhYNqwG7zjFkFFsw9baK1d80e8odZppMmQE8S6Q7cBuD9ruc1v9iZH3Njj%7Expp7VWm-7C8rAXH3P3K7Spm%7ETOY%7EGz3LzMBVyZH6RDIFYvaXClR%7EOhsFxlVJgJqZRkEwvcEWhr7d1hPAmmsdvkkjKUVhJTOv64l2KGd52FKIpzwyHl10g3r9ZPIi9x%7E4gq8LSreh-eHKGtTr82Rz5g6s0fZ1kwGKbl13oVJHFb3wjX%7EM-WSiVnYuOf9Usi-NBUCPNu2ndUCJ5%7EIxE4ZKcANHwbIe%7Eaua2nUpzAKzSJ1M2eKc8g0t-vCBLfu-SwKleXi4AQ5uTeNvoAS0Up3DA__&Key-Pair-Id=K3RPWS32NSSJCE [following]\n",
            "--2025-05-16 01:17:27--  https://cdn-lfs.hf.co/repos/80/a9/80a9efd8e3732d097f2777edd953760ce288e2370fb8a8bb4803c0f8f29dca40/cf16ea656cb16124990c8e2c70a29c793f9841f3a2223073fac8bd89ebd9b69a?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27mm_sd_v15.ckpt%3B+filename%3D%22mm_sd_v15.ckpt%22%3B&Expires=1747361847&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzM2MTg0N319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5oZi5jby9yZXBvcy84MC9hOS84MGE5ZWZkOGUzNzMyZDA5N2YyNzc3ZWRkOTUzNzYwY2UyODhlMjM3MGZiOGE4YmI0ODAzYzBmOGYyOWRjYTQwL2NmMTZlYTY1NmNiMTYxMjQ5OTBjOGUyYzcwYTI5Yzc5M2Y5ODQxZjNhMjIyMzA3M2ZhYzhiZDg5ZWJkOWI2OWE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=SmzOUWxhYNqwG7zjFkFFsw9baK1d80e8odZppMmQE8S6Q7cBuD9ruc1v9iZH3Njj%7Expp7VWm-7C8rAXH3P3K7Spm%7ETOY%7EGz3LzMBVyZH6RDIFYvaXClR%7EOhsFxlVJgJqZRkEwvcEWhr7d1hPAmmsdvkkjKUVhJTOv64l2KGd52FKIpzwyHl10g3r9ZPIi9x%7E4gq8LSreh-eHKGtTr82Rz5g6s0fZ1kwGKbl13oVJHFb3wjX%7EM-WSiVnYuOf9Usi-NBUCPNu2ndUCJ5%7EIxE4ZKcANHwbIe%7Eaua2nUpzAKzSJ1M2eKc8g0t-vCBLfu-SwKleXi4AQ5uTeNvoAS0Up3DA__&Key-Pair-Id=K3RPWS32NSSJCE\n",
            "Resolving cdn-lfs.hf.co (cdn-lfs.hf.co)... 3.169.231.115, 3.169.231.38, 3.169.231.87, ...\n",
            "Connecting to cdn-lfs.hf.co (cdn-lfs.hf.co)|3.169.231.115|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1672133921 (1.6G) [binary/octet-stream]\n",
            "Saving to: ‘extensions/sd-webui-animatediff/model/mm_sd_v15.ckpt’\n",
            "\n",
            "extensions/sd-webui 100%[===================>]   1.56G  93.4MB/s    in 14s     \n",
            "\n",
            "2025-05-16 01:17:41 (117 MB/s) - ‘extensions/sd-webui-animatediff/model/mm_sd_v15.ckpt’ saved [1672133921/1672133921]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python launch.py --share --no-half --precision full --disable-safe-unpickle --lowvram --enable-insecure-extension-access\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5OVCq5FuNkx",
        "outputId": "3c9da175-e4ff-4744-c90a-410a37db6cff"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.11.12 (main, Apr  9 2025, 08:55:54) [GCC 11.4.0]\n",
            "Version: v1.10.1\n",
            "Commit hash: 82a973c04367123ae98bd9abdf80d9eda9b910e2\n",
            "Launching Web UI with arguments: --share --no-half --precision full --disable-safe-unpickle --lowvram --enable-insecure-extension-access\n",
            "2025-05-16 01:55:00.137811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1747360500.157935    9636 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1747360500.163946    9636 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "WARNING:xformers:WARNING[XFORMERS]: xFormers can't load C++/CUDA extensions. xFormers was built for:\n",
            "    PyTorch 2.1.2+cu121 with CUDA 1201 (you have 2.6.0+cu124)\n",
            "    Python  3.11.7 (you have 3.11.12)\n",
            "  Please reinstall xformers (see https://github.com/facebookresearch/xformers#installing-xformers)\n",
            "  Memory-efficient attention, SwiGLU, sparse and more won't be available.\n",
            "  Set XFORMERS_MORE_DETAILS=1 for more details\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/triton/softmax.py:30: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd(cast_inputs=torch.float16 if _triton_softmax_fp16_enabled else None)\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/triton/softmax.py:86: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/swiglu_op.py:106: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd\n",
            "/usr/local/lib/python3.11/dist-packages/xformers/ops/swiglu_op.py:127: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_bwd\n",
            "No module 'xformers'. Proceeding without it.\n",
            "Loading weights [84ce473cde] from /content/stable-diffusion-webui/models/Stable-diffusion/NSFW_master.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:943: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "Applying attention optimization: Doggettx... done.\n",
            "Model loaded in 3.7s (create model: 0.9s, apply weights to model: 2.3s, calculate empty prompt: 0.3s).\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://d65f96bbb0ddf15dec.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 19.0s (prepare environment: 2.3s, import torch: 6.1s, import gradio: 0.8s, setup paths: 3.6s, initialize shared: 0.2s, other imports: 0.3s, load scripts: 1.1s, create ui: 4.1s, gradio launch: 0.4s).\n",
            "  0% 0/20 [00:00<?, ?it/s]\n",
            "  5% 1/20 [00:05<01:41,  5.34s/it]\n",
            " 10% 2/20 [00:09<01:22,  4.58s/it]\n",
            " 15% 3/20 [00:12<01:10,  4.12s/it]\n",
            " 20% 4/20 [00:16<01:01,  3.86s/it]\n",
            " 25% 5/20 [00:20<01:00,  4.06s/it]\n",
            "\n",
            "Total progress:  25% 5/20 [00:15<00:47,  3.19s/it]\n",
            "2025-05-16 01:57:36,081 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - AnimateDiff process start.\n",
            "2025-05-16 01:57:36,081 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Loading motion module mm_sd_v15.ckpt from /content/stable-diffusion-webui/extensions/sd-webui-animatediff/model/mm_sd_v15.ckpt\n",
            "2025-05-16 01:57:38,317 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Guessed mm_sd_v15.ckpt architecture: MotionModuleType.AnimateDiffV1\n",
            "2025-05-16 01:57:43,118 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Hacking SD1.5 GroupNorm32 forward function.\n",
            "2025-05-16 01:57:43,119 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injecting motion module mm_sd_v15.ckpt into SD1.5 UNet input blocks.\n",
            "2025-05-16 01:57:43,119 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injecting motion module mm_sd_v15.ckpt into SD1.5 UNet output blocks.\n",
            "2025-05-16 01:57:43,119 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Setting DDIM alpha.\n",
            "2025-05-16 01:57:43,160 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injection finished.\n",
            "2025-05-16 01:57:43,160 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - AnimateDiff + ControlNet will generate 8 frames.\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-05-16 01:57:43,523 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - inner model forward hooked\n",
            "\n",
            "  5% 1/20 [00:18<05:43, 18.10s/it]\n",
            " 10% 2/20 [00:35<05:23, 17.97s/it]\n",
            " 15% 3/20 [00:54<05:09, 18.19s/it]\n",
            " 20% 4/20 [01:12<04:52, 18.26s/it]\n",
            " 25% 5/20 [01:31<04:35, 18.33s/it]\n",
            " 30% 6/20 [01:49<04:15, 18.26s/it]\n",
            " 35% 7/20 [02:07<03:57, 18.31s/it]\n",
            " 40% 8/20 [02:26<03:39, 18.33s/it]\n",
            " 45% 9/20 [02:44<03:22, 18.38s/it]\n",
            " 50% 10/20 [03:02<03:03, 18.36s/it]\n",
            " 55% 11/20 [03:21<02:45, 18.39s/it]\n",
            " 60% 12/20 [03:39<02:26, 18.36s/it]\n",
            " 65% 13/20 [04:11<02:15, 19.38s/it]\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(gnt6zlxzli03apg)', <gradio.routes.Request object at 0x7b402c22de90>, 'girl completely naked in the river touching her huge tits', 'blurry, bad anatomy, deformed', [], 1, 1, 7, 768, 512, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', 'Use same scheduler', '', '', [], 0, 20, 'DPM++ 2M', 'Automatic', True, 'NSFW_master.safetensors [84ce473cde]', 0.8, -1, False, -1, 0, 0, 0, <scripts.animatediff_ui.AnimateDiffProcess object at 0x7b402c198790>, False, False, 'positive', 'comma', 0, False, False, 'start', '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 109, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 847, in process_images\n",
            "        res = process_images_inner(p)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 988, in process_images_inner\n",
            "        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 1346, in sample\n",
            "        samples = self.sampler.sample(self, x, conditioning, unconditional_conditioning, image_conditioning=self.txt2img_image_conditioning(x))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 230, in sample\n",
            "        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_common.py\", line 272, in launch_sampling\n",
            "        return func()\n",
            "               ^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 230, in <lambda>\n",
            "        samples = self.launch_sampling(steps, lambda: self.func(self.model_wrap_cfg, x, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                                                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "        return func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/sampling.py\", line 594, in sample_dpmpp_2m\n",
            "        denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_cfg_denoiser.py\", line 249, in forward\n",
            "        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "        return self.inner_model.apply_model(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 50, in apply_model\n",
            "        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 36, in __call__\n",
            "        return self.__orig_func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "        x_recon = self.model(x_noisy, t, **cond)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1335, in forward\n",
            "        out = self.diffusion_model(x, t, context=cc)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_unet.py\", line 91, in UNetModel_forward\n",
            "        return original_forward(self, x, timesteps, context, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/openaimodel.py\", line 802, in forward\n",
            "        h = module(h, emb, context)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1845, in _call_impl\n",
            "        return inner()\n",
            "               ^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1793, in inner\n",
            "        result = forward_call(*args, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "        x = layer(x, context)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 96, in spatial_transformer_forward\n",
            "        x = block(x, context=context[i])\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/attention.py\", line 269, in forward\n",
            "        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/util.py\", line 123, in checkpoint\n",
            "        return func(*inputs)\n",
            "               ^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/attention.py\", line 272, in _forward\n",
            "        x = self.attn1(self.norm1(x), context=context if self.disable_self_attn else None) + x\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 268, in split_cross_attention_forward\n",
            "        s2 = s1.softmax(dim=-1, dtype=q.dtype)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.50 GiB. GPU 0 has a total capacity of 14.74 GiB of which 2.67 GiB is free. Process 116445 has 12.07 GiB memory in use. Of the allocated memory 7.39 GiB is allocated by PyTorch, and 4.55 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "---\n",
            "2025-05-16 02:04:35,223 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - AnimateDiff process start.\n",
            "2025-05-16 02:04:35,223 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Motion module already injected. Trying to restore.\n",
            "2025-05-16 02:04:35,223 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Restoring DDIM alpha.\n",
            "2025-05-16 02:04:35,224 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Removing motion module from SD1.5 UNet input blocks.\n",
            "2025-05-16 02:04:35,224 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Removing motion module from SD1.5 UNet output blocks.\n",
            "2025-05-16 02:04:35,224 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Restoring SD1.5 GroupNorm32 forward function.\n",
            "2025-05-16 02:04:35,226 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Removal finished.\n",
            "2025-05-16 02:04:35,226 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Moving motion module to CPU\n",
            "2025-05-16 02:04:36,325 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Hacking SD1.5 GroupNorm32 forward function.\n",
            "2025-05-16 02:04:36,326 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injecting motion module mm_sd_v15.ckpt into SD1.5 UNet input blocks.\n",
            "2025-05-16 02:04:36,326 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injecting motion module mm_sd_v15.ckpt into SD1.5 UNet output blocks.\n",
            "2025-05-16 02:04:36,326 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Setting DDIM alpha.\n",
            "2025-05-16 02:04:36,331 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injection finished.\n",
            "2025-05-16 02:04:36,331 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - AnimateDiff + ControlNet will generate 8 frames.\n",
            "2025-05-16 02:04:38,290 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Randomizing init_latent according to [1.0, 0.96875, 0.9375, 0.90625, 0.875, 0.84375, 0.8125, 0.78125].\n",
            "*** Error running before_process_batch: /content/stable-diffusion-webui/extensions/sd-webui-animatediff/scripts/animatediff.py\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/scripts.py\", line 848, in before_process_batch\n",
            "        script.before_process_batch(p, *script_args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-animatediff/scripts/animatediff.py\", line 79, in before_process_batch\n",
            "        AnimateDiffI2VLatent().randomize(p, params)\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-animatediff/scripts/animatediff_latent.py\", line 84, in randomize\n",
            "        p.init_latent = p.init_latent * init_alpha + p.rng.next() * (1 - init_alpha)\n",
            "                        ~~~~~~~~~~~~~~^~~~~~~~~~~~\n",
            "    RuntimeError: The size of tensor a (16) must match the size of tensor b (8) at non-singleton dimension 0\n",
            "\n",
            "---\n",
            "  0% 0/14 [00:00<?, ?it/s]2025-05-16 02:04:38,657 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - inner model forward hooked\n",
            "\n",
            "  7% 1/14 [00:08<01:53,  8.70s/it]\n",
            " 14% 2/14 [00:16<01:39,  8.31s/it]\n",
            " 21% 3/14 [00:24<01:30,  8.23s/it]\n",
            " 29% 4/14 [00:33<01:22,  8.28s/it]\n",
            " 36% 5/14 [00:41<01:13,  8.16s/it]\n",
            " 43% 6/14 [00:49<01:05,  8.15s/it]\n",
            " 50% 7/14 [01:04<01:04,  9.20s/it]\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(kp73zbig4jcz3gr)', <gradio.routes.Request object at 0x7b402379ccd0>, 0, 'girl completely naked in the river touching her huge tits', 'blurry, bad anatomy, deformed, different-person ', [], <PIL.Image.Image image mode=RGBA size=277x649 at 0x7B402375D710>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.65, 0.0, 512, 277, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 20, 'DPM++ 2M', 'Automatic', True, 'NSFW_master.safetensors [84ce473cde]', 0.8, -1, False, -1, 0, 0, 0, <scripts.animatediff_ui.AnimateDiffProcess object at 0x7b402c3f6910>, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=\"margin-bottom:0.75em\">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=\"margin-bottom:0.75em\">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/img2img.py\", line 242, in img2img\n",
            "        processed = process_images(p)\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 847, in process_images\n",
            "        res = process_images_inner(p)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 988, in process_images_inner\n",
            "        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 1774, in sample\n",
            "        samples = self.sampler.sample_img2img(self, self.init_latent, x, conditioning, unconditional_conditioning, image_conditioning=self.image_conditioning)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 184, in sample_img2img\n",
            "        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_common.py\", line 272, in launch_sampling\n",
            "        return func()\n",
            "               ^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 184, in <lambda>\n",
            "        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "        return func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/sampling.py\", line 594, in sample_dpmpp_2m\n",
            "        denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_cfg_denoiser.py\", line 249, in forward\n",
            "        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "        return self.inner_model.apply_model(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 50, in apply_model\n",
            "        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 36, in __call__\n",
            "        return self.__orig_func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "        x_recon = self.model(x_noisy, t, **cond)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1335, in forward\n",
            "        out = self.diffusion_model(x, t, context=cc)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_unet.py\", line 91, in UNetModel_forward\n",
            "        return original_forward(self, x, timesteps, context, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/openaimodel.py\", line 802, in forward\n",
            "        h = module(h, emb, context)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1845, in _call_impl\n",
            "        return inner()\n",
            "               ^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1793, in inner\n",
            "        result = forward_call(*args, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "        x = layer(x, context)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 96, in spatial_transformer_forward\n",
            "        x = block(x, context=context[i])\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/attention.py\", line 269, in forward\n",
            "        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/util.py\", line 123, in checkpoint\n",
            "        return func(*inputs)\n",
            "               ^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/attention.py\", line 272, in _forward\n",
            "        x = self.attn1(self.norm1(x), context=context if self.disable_self_attn else None) + x\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 268, in split_cross_attention_forward\n",
            "        s2 = s1.softmax(dim=-1, dtype=q.dtype)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.52 GiB. GPU 0 has a total capacity of 14.74 GiB of which 4.43 GiB is free. Process 116445 has 10.31 GiB memory in use. Of the allocated memory 5.59 GiB is allocated by PyTorch, and 4.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "---\n",
            "2025-05-16 02:06:52,947 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - AnimateDiff process start.\n",
            "2025-05-16 02:06:52,947 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Motion module already injected. Trying to restore.\n",
            "2025-05-16 02:06:52,948 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Restoring DDIM alpha.\n",
            "2025-05-16 02:06:52,948 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Removing motion module from SD1.5 UNet input blocks.\n",
            "2025-05-16 02:06:52,948 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Removing motion module from SD1.5 UNet output blocks.\n",
            "2025-05-16 02:06:52,948 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Restoring SD1.5 GroupNorm32 forward function.\n",
            "2025-05-16 02:06:52,949 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Removal finished.\n",
            "2025-05-16 02:06:52,949 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Moving motion module to CPU\n",
            "2025-05-16 02:06:54,004 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Hacking SD1.5 GroupNorm32 forward function.\n",
            "2025-05-16 02:06:54,004 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injecting motion module mm_sd_v15.ckpt into SD1.5 UNet input blocks.\n",
            "2025-05-16 02:06:54,004 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injecting motion module mm_sd_v15.ckpt into SD1.5 UNet output blocks.\n",
            "2025-05-16 02:06:54,005 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Setting DDIM alpha.\n",
            "2025-05-16 02:06:54,010 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Injection finished.\n",
            "2025-05-16 02:06:54,010 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - AnimateDiff + ControlNet will generate 257 frames.\n",
            "2025-05-16 02:07:22,589 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Randomizing init_latent according to [1.0, 0.96875, 0.9375, 0.90625, 0.875, 0.84375, 0.8125, 0.78125, 0.75, 0.71875, 0.6875, 0.65625, 0.625, 0.59375, 0.5625, 0.53125, 0.5, 0.46875, 0.4375, 0.40625, 0.375, 0.34375, 0.3125, 0.28125, 0.25, 0.21875, 0.1875, 0.15625, 0.125, 0.09375, 0.0625, 0.03125, 0.0, -0.03125, -0.0625, -0.09375, -0.125, -0.15625, -0.1875, -0.21875, -0.25, -0.28125, -0.3125, -0.34375, -0.375, -0.40625, -0.4375, -0.46875, -0.5, -0.53125, -0.5625, -0.59375, -0.625, -0.65625, -0.6875, -0.71875, -0.75, -0.78125, -0.8125, -0.84375, -0.875, -0.90625, -0.9375, -0.96875, -1.0, -1.03125, -1.0625, -1.09375, -1.125, -1.15625, -1.1875, -1.21875, -1.25, -1.28125, -1.3125, -1.34375, -1.375, -1.40625, -1.4375, -1.46875, -1.5, -1.53125, -1.5625, -1.59375, -1.625, -1.65625, -1.6875, -1.71875, -1.75, -1.78125, -1.8125, -1.84375, -1.875, -1.90625, -1.9375, -1.96875, -2.0, -2.03125, -2.0625, -2.09375, -2.125, -2.15625, -2.1875, -2.21875, -2.25, -2.28125, -2.3125, -2.34375, -2.375, -2.40625, -2.4375, -2.46875, -2.5, -2.53125, -2.5625, -2.59375, -2.625, -2.65625, -2.6875, -2.71875, -2.75, -2.78125, -2.8125, -2.84375, -2.875, -2.90625, -2.9375, -2.96875, -3.0, -3.03125, -3.0625, -3.09375, -3.125, -3.15625, -3.1875, -3.21875, -3.25, -3.28125, -3.3125, -3.34375, -3.375, -3.40625, -3.4375, -3.46875, -3.5, -3.53125, -3.5625, -3.59375, -3.625, -3.65625, -3.6875, -3.71875, -3.75, -3.78125, -3.8125, -3.84375, -3.875, -3.90625, -3.9375, -3.96875, -4.0, -4.03125, -4.0625, -4.09375, -4.125, -4.15625, -4.1875, -4.21875, -4.25, -4.28125, -4.3125, -4.34375, -4.375, -4.40625, -4.4375, -4.46875, -4.5, -4.53125, -4.5625, -4.59375, -4.625, -4.65625, -4.6875, -4.71875, -4.75, -4.78125, -4.8125, -4.84375, -4.875, -4.90625, -4.9375, -4.96875, -5.0, -5.03125, -5.0625, -5.09375, -5.125, -5.15625, -5.1875, -5.21875, -5.25, -5.28125, -5.3125, -5.34375, -5.375, -5.40625, -5.4375, -5.46875, -5.5, -5.53125, -5.5625, -5.59375, -5.625, -5.65625, -5.6875, -5.71875, -5.75, -5.78125, -5.8125, -5.84375, -5.875, -5.90625, -5.9375, -5.96875, -6.0, -6.03125, -6.0625, -6.09375, -6.125, -6.15625, -6.1875, -6.21875, -6.25, -6.28125, -6.3125, -6.34375, -6.375, -6.40625, -6.4375, -6.46875, -6.5, -6.53125, -6.5625, -6.59375, -6.625, -6.65625, -6.6875, -6.71875, -6.75, -6.78125, -6.8125, -6.84375, -6.875, -6.90625, -6.9375, -6.96875, -7.0].\n",
            "2025-05-16 02:07:22,590 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - Randomizing last_latent according to [-7.0, -6.96875, -6.9375, -6.90625, -6.875, -6.84375, -6.8125, -6.78125, -6.75, -6.71875, -6.6875, -6.65625, -6.625, -6.59375, -6.5625, -6.53125, -6.5, -6.46875, -6.4375, -6.40625, -6.375, -6.34375, -6.3125, -6.28125, -6.25, -6.21875, -6.1875, -6.15625, -6.125, -6.09375, -6.0625, -6.03125, -6.0, -5.96875, -5.9375, -5.90625, -5.875, -5.84375, -5.8125, -5.78125, -5.75, -5.71875, -5.6875, -5.65625, -5.625, -5.59375, -5.5625, -5.53125, -5.5, -5.46875, -5.4375, -5.40625, -5.375, -5.34375, -5.3125, -5.28125, -5.25, -5.21875, -5.1875, -5.15625, -5.125, -5.09375, -5.0625, -5.03125, -5.0, -4.96875, -4.9375, -4.90625, -4.875, -4.84375, -4.8125, -4.78125, -4.75, -4.71875, -4.6875, -4.65625, -4.625, -4.59375, -4.5625, -4.53125, -4.5, -4.46875, -4.4375, -4.40625, -4.375, -4.34375, -4.3125, -4.28125, -4.25, -4.21875, -4.1875, -4.15625, -4.125, -4.09375, -4.0625, -4.03125, -4.0, -3.96875, -3.9375, -3.90625, -3.875, -3.84375, -3.8125, -3.78125, -3.75, -3.71875, -3.6875, -3.65625, -3.625, -3.59375, -3.5625, -3.53125, -3.5, -3.46875, -3.4375, -3.40625, -3.375, -3.34375, -3.3125, -3.28125, -3.25, -3.21875, -3.1875, -3.15625, -3.125, -3.09375, -3.0625, -3.03125, -3.0, -2.96875, -2.9375, -2.90625, -2.875, -2.84375, -2.8125, -2.78125, -2.75, -2.71875, -2.6875, -2.65625, -2.625, -2.59375, -2.5625, -2.53125, -2.5, -2.46875, -2.4375, -2.40625, -2.375, -2.34375, -2.3125, -2.28125, -2.25, -2.21875, -2.1875, -2.15625, -2.125, -2.09375, -2.0625, -2.03125, -2.0, -1.96875, -1.9375, -1.90625, -1.875, -1.84375, -1.8125, -1.78125, -1.75, -1.71875, -1.6875, -1.65625, -1.625, -1.59375, -1.5625, -1.53125, -1.5, -1.46875, -1.4375, -1.40625, -1.375, -1.34375, -1.3125, -1.28125, -1.25, -1.21875, -1.1875, -1.15625, -1.125, -1.09375, -1.0625, -1.03125, -1.0, -0.96875, -0.9375, -0.90625, -0.875, -0.84375, -0.8125, -0.78125, -0.75, -0.71875, -0.6875, -0.65625, -0.625, -0.59375, -0.5625, -0.53125, -0.5, -0.46875, -0.4375, -0.40625, -0.375, -0.34375, -0.3125, -0.28125, -0.25, -0.21875, -0.1875, -0.15625, -0.125, -0.09375, -0.0625, -0.03125, 0.0, 0.03125, 0.0625, 0.09375, 0.125, 0.15625, 0.1875, 0.21875, 0.25, 0.28125, 0.3125, 0.34375, 0.375, 0.40625, 0.4375, 0.46875, 0.5, 0.53125, 0.5625, 0.59375, 0.625, 0.65625, 0.6875, 0.71875, 0.75, 0.78125, 0.8125, 0.84375, 0.875, 0.90625, 0.9375, 0.96875, 1.0].\n",
            "  0% 0/20 [00:00<?, ?it/s]2025-05-16 02:07:23,290 - AnimateDiff - \u001b[0;32mINFO\u001b[0m - inner model forward hooked\n",
            "  0% 0/20 [00:00<?, ?it/s]\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(ngs9kag6r5m18ut)', <gradio.routes.Request object at 0x7b4023702ed0>, 0, 'girl completely naked in the river touching her huge tits', 'blurry, bad anatomy, deformed, different-person ', [], <PIL.Image.Image image mode=RGBA size=277x649 at 0x7B4028C6F5D0>, None, None, None, None, None, None, 4, 0, 1, 1, 1, 7, 1.5, 0.65, 0.0, 512, 277, 1, 0, 0, 32, 0, '', '', '', [], False, [], '', 'upload', None, 0, False, 1, 0.5, 4, 0, 0.5, 2, 30, 'DPM++ 2M', 'Automatic', True, 'NSFW_master.safetensors [84ce473cde]', 0.8, -1, False, -1, 0, 0, 0, <scripts.animatediff_ui.AnimateDiffProcess object at 0x7b402379c7d0>, '* `CFG Scale` should be 2 or lower.', True, True, '', '', True, 50, True, 1, 0, False, 4, 0.5, 'Linear', 'None', '<p style=\"margin-bottom:0.75em\">Recommended settings: Sampling Steps: 80-100, Sampler: Euler a, Denoising strength: 0.8</p>', 128, 8, ['left', 'right', 'up', 'down'], 1, 0.05, 128, 4, 0, ['left', 'right', 'up', 'down'], False, False, 'positive', 'comma', 0, False, False, 'start', '', '<p style=\"margin-bottom:0.75em\">Will upscale the image by the selected scale factor; use width and height sliders to set tile size</p>', 64, 0, 2, 1, '', [], 0, '', [], 0, '', [], True, False, False, False, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 74, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 53, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 37, in f\n",
            "        res = func(*args, **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/img2img.py\", line 242, in img2img\n",
            "        processed = process_images(p)\n",
            "                    ^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 847, in process_images\n",
            "        res = process_images_inner(p)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 988, in process_images_inner\n",
            "        samples_ddim = p.sample(conditioning=p.c, unconditional_conditioning=p.uc, seeds=p.seeds, subseeds=p.subseeds, subseed_strength=p.subseed_strength, prompts=p.prompts)\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 1774, in sample\n",
            "        samples = self.sampler.sample_img2img(self, self.init_latent, x, conditioning, unconditional_conditioning, image_conditioning=self.image_conditioning)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 184, in sample_img2img\n",
            "        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_common.py\", line 272, in launch_sampling\n",
            "        return func()\n",
            "               ^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_kdiffusion.py\", line 184, in <lambda>\n",
            "        samples = self.launch_sampling(t_enc + 1, lambda: self.func(self.model_wrap_cfg, xi, extra_args=self.sampler_extra_args, disable=False, callback=self.callback_state, **extra_params_kwargs))\n",
            "                                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "        return func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/sampling.py\", line 594, in sample_dpmpp_2m\n",
            "        denoised = model(x, sigmas[i] * s_in, **extra_args)\n",
            "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_samplers_cfg_denoiser.py\", line 249, in forward\n",
            "        x_out = self.inner_model(x_in, sigma_in, cond=make_condition_dict(cond_in, image_cond_in))\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/extensions/sd-webui-animatediff/scripts/animatediff_infv2v.py\", line 163, in mm_sd_forward\n",
            "        out = self.original_forward(\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/external.py\", line 112, in forward\n",
            "        eps = self.get_eps(input * c_in, self.sigma_to_t(sigma), **kwargs)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/k-diffusion/k_diffusion/external.py\", line 138, in get_eps\n",
            "        return self.inner_model.apply_model(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 50, in apply_model\n",
            "        result = orig_func(self, x_noisy.to(devices.dtype_unet), t.to(devices.dtype_unet), cond, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 36, in __call__\n",
            "        return self.__orig_func(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 858, in apply_model\n",
            "        x_recon = self.model(x_noisy, t, **cond)\n",
            "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 1335, in forward\n",
            "        out = self.diffusion_model(x, t, context=cc)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_unet.py\", line 91, in UNetModel_forward\n",
            "        return original_forward(self, x, timesteps, context, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/openaimodel.py\", line 797, in forward\n",
            "        h = module(h, emb, context)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1845, in _call_impl\n",
            "        return inner()\n",
            "               ^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1793, in inner\n",
            "        result = forward_call(*args, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/openaimodel.py\", line 84, in forward\n",
            "        x = layer(x, context)\n",
            "            ^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 22, in <lambda>\n",
            "        setattr(resolved_obj, func_path[-1], lambda *args, **kwargs: self(*args, **kwargs))\n",
            "                                                                     ^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_utils.py\", line 34, in __call__\n",
            "        return self.__sub_func(self.__orig_func, *args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_unet.py\", line 96, in spatial_transformer_forward\n",
            "        x = block(x, context=context[i])\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/attention.py\", line 269, in forward\n",
            "        return checkpoint(self._forward, (x, context), self.parameters(), self.checkpoint)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/diffusionmodules/util.py\", line 123, in checkpoint\n",
            "        return func(*inputs)\n",
            "               ^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/attention.py\", line 272, in _forward\n",
            "        x = self.attn1(self.norm1(x), context=context if self.disable_self_attn else None) + x\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "        return self._call_impl(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "      File \"/content/stable-diffusion-webui/modules/sd_hijack_optimizations.py\", line 268, in split_cross_attention_forward\n",
            "        s2 = s1.softmax(dim=-1, dtype=q.dtype)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "    torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 4.52 GiB. GPU 0 has a total capacity of 14.74 GiB of which 2.62 GiB is free. Process 116445 has 12.12 GiB memory in use. Of the allocated memory 7.15 GiB is allocated by PyTorch, and 4.85 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)\n",
            "\n",
            "---\n",
            "Interrupted with signal 2 in <frame at 0x7b402376fe60, file '/usr/lib/python3.11/threading.py', line 331, code wait>\n"
          ]
        }
      ]
    }
  ]
}